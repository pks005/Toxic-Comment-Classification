Step 1:
Set your current working directory to "Toxic-Comment-Classification" folder
Use this code:
import os
os.chdir('folder path')


Step 2:
Run in the following sequence:

1. Toxic Comment Classification-toxic.ipynb
2. Toxic Comment Classification-obscene.ipynb
3. Toxic Comment Classification-severe_toxic.ipynb
4. Toxic Comment Classification-threat.ipynb
5. Toxic Comment Classification-insult.ipynb
6. Toxic Comment Classification-identity_hate.ipynb



NOTE:

1. Predicted probabilities are in the file named "sample_submission.csv" present in the main folder.

2. If any problem is found in datasets(train.csv and test.csv) then the datasets can be directly downloaded from kaggle Toxic comment classification challenge. Download from the below link:
https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/data
